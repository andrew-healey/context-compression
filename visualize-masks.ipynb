{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from contextlib import nullcontext\n",
    "import torch\n",
    "import tiktoken\n",
    "from tqdm import tqdm\n",
    "from torch.nn import functional as F\n",
    "from context_compression.model import GPT, GPTConfig\n",
    "from context_compression.attn import AttentionKind\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "init_from = 'resume' # either 'resume' (from an out_dir) or a gpt2 variant (e.g. 'gpt2-xl')\n",
    "out_dir = 'out' # ignored if init_from is not 'resume'\n",
    "start = \"Hello, I'm a language model,\" # or \"<|endoftext|>\" or etc. Can also specify a file, use as: \"FILE:prompt.txt\"\n",
    "num_samples = 10 # number of samples to draw\n",
    "max_new_tokens = 256 # number of tokens generated in each sample\n",
    "temperature = 0.8 # 1.0 = no change, < 1.0 = less random, > 1.0 = more random, in predictions\n",
    "top_k = 200 # retain only the top_k most likely tokens, clamp others to have 0 probability\n",
    "seed = 1337\n",
    "device = 'cuda' # examples: 'cpu', 'cuda', 'cuda:0', 'cuda:1', etc.\n",
    "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32' or 'bfloat16' or 'float16'\n",
    "compile = True # use PyTorch 2.0 to compile the model to be faster\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul\n",
    "torch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn\n",
    "device_type = 'cuda' if 'cuda' in device else 'cpu' # for later use in torch.autocast\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
    "\n",
    "# init from a model saved in a specific directory\n",
    "\n",
    "\n",
    "# model = GPT(GPTConfig(attention_kind=AttentionKind.SELECTIVE, for_inference=True, vocab_size=50304))\n",
    "# ckpt_path = \"/workspace/context-compression/selective_run_0_continued/model_09999.pt\"\n",
    "\n",
    "# model = GPT(GPTConfig(attention_kind=AttentionKind.SELECTIVE, for_inference=True, vocab_size=50304))\n",
    "# ckpt_path = \"/workspace/context-compression/selective_run_0_continued/model_09999.pt\"\n",
    "\n",
    "# model = GPT(GPTConfig(attention_kind=AttentionKind.SELECTIVE, for_inference=False, vocab_size=50304))\n",
    "# ckpt_path = \"/workspace/context-compression/memory_loss_run_0/model_09999.pt\"\n",
    "\n",
    "# model = GPT(GPTConfig(attention_kind=AttentionKind.SELF, for_inference=True, vocab_size=50304))\n",
    "# ckpt_path = \"/workspace/context-compression/unselective_run_0/model_09999.pt\"\n",
    "\n",
    "# model = GPT(GPTConfig(attention_kind=AttentionKind.SELECTIVE, for_inference=False, vocab_size=50304))\n",
    "# ckpt_path = \"/root/.cache/huggingface/hub/models--Yorth--selective1/snapshots/1d3d987c90be4b8d6f58de60749ba5823f0ecd29/model.pt\"\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "# config = GPTConfig(attention_kind=AttentionKind.SELECTIVE, for_inference=True, vocab_size=50304,n_head=13)\n",
    "# model = GPT(config)\n",
    "# ckpt_path = hf_hub_download(repo_id=\"andrew-healey/context-compression\",filename=\"self_to_selective_run_0_restarted/model_02499.pt\")\n",
    "# config = GPTConfig(attention_kind=AttentionKind.SELECTIVE, for_inference=True, vocab_size=50304,n_head=13)\n",
    "# ckpt_path = hf_hub_download(repo_id=\"andrew-healey/context-compression\",filename=\"protection_none_torch_compile/model_02499.pt\")\n",
    "# new_eps_ratios, new_eps_losses = get_validation_loss_at_diff_ratios(new_config, ckpt_path)\n",
    "\n",
    "config = GPTConfig(attention_kind=AttentionKind.SELECTIVE, for_inference=True, vocab_size=50304)\n",
    "model = GPT(config)\n",
    "ckpt_path = hf_hub_download(repo_id=\"Yorth/selective1\",filename=\"model.pt\")\n",
    "\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "\n",
    "state_dict = checkpoint['model']\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k,v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "model.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize input text using GPT-2 tokenizer\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "text = \"Hello world!\"\n",
    "tokens = enc.encode(text)\n",
    "tokens = torch.tensor(tokens).unsqueeze(0).to(device) # Add batch dimension and move to device\n",
    "\n",
    "ff_cache = []\n",
    "\n",
    "# Run through model\n",
    "with torch.no_grad():\n",
    "    with ctx:\n",
    "        logits, loss, losses = model(tokens,ff_cache=ff_cache)\n",
    "        \n",
    "print(f\"Input tokens: {tokens}\")\n",
    "print(f\"Output logits shape: {logits.shape}\")\n",
    "\n",
    "\n",
    "T,Tp = ff_cache[0].squeeze(0).shape\n",
    "\n",
    "# Plot the attention masks as a bitmap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Take the first layer's mask from the first batch\n",
    "mask = ff_cache[0].squeeze(0)  # Shape: [T,Tp]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(mask, cmap='viridis', aspect='equal')\n",
    "plt.colorbar(label='Mask Value')\n",
    "plt.title('Attention Mask')\n",
    "plt.xlabel('Key Position')\n",
    "plt.ylabel('Query Position') \n",
    "plt.show()\n",
    "\n",
    "# Optionally plot masks from all layers\n",
    "fig, axes = plt.subplots(len(ff_cache), 1, figsize=(10, 4*len(ff_cache)))\n",
    "for i, layer_mask in enumerate(ff_cache):\n",
    "    mask = layer_mask[0]  # Take first batch\n",
    "    axes[i].imshow(mask, cmap='RdYlGn_r', vmin=0, vmax=mask.max(), aspect='equal')\n",
    "    axes[i].set_title(f'Layer {i} Mask')\n",
    "    axes[i].set_xlabel('Key Position')\n",
    "    axes[i].set_ylabel('Query Position')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
